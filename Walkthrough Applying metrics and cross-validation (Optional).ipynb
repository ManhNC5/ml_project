{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257984a6-18d4-4e99-b92f-ede5634419dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e753812a-1970-4fb3-8e14-ea7c628b3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'StudyHours': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'PrevExamScore': [30, 40, 45, 50, 60, 65, 70, 75, 80, 85],\n",
    "    'Pass': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  # 0 = Fail, 1 = Pass\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd59a0ef-8081-4c8f-9439-49c0372a0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Features and target variable\n",
    "X = df[['StudyHours', 'PrevExamScore']]\n",
    "y = df['Pass']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a95e02-3841-4ef6-9911-6d12e35ca4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6084049-1cfe-4a83-ab7c-e0d7bdb7e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracies: [1.  1.  1.  1.  0.5]\n",
      "Mean cross-validation accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation and calculate accuracy for each fold\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Display the accuracy for each fold and the mean accuracy\n",
    "print(f'Cross-validation accuracies: {cv_scores}')\n",
    "print(f'Mean cross-validation accuracy: {cv_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8960b24d-480c-4aae-87ef-caa90672e98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy: 0.9\n",
      "Cross-validation Precision: 0.9\n",
      "Cross-validation Recall: 1.0\n",
      "Cross-validation F1-Score: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Define multiple scoring metrics\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "# Print results for each metric\n",
    "print(f\"Cross-validation Accuracy: {np.mean(cv_results['test_accuracy'])}\")\n",
    "print(f\"Cross-validation Precision: {np.mean(cv_results['test_precision'])}\")\n",
    "print(f\"Cross-validation Recall: {np.mean(cv_results['test_recall'])}\")\n",
    "print(f\"Cross-validation F1-Score: {np.mean(cv_results['test_f1'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f06c1d-f18a-475f-a6a7-be9e9e44e494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation R-squared scores: [ 0.52933673  0.88503086 -0.60298929  0.88503086 -1.28939909]\n",
      "Mean R-squared score: 0.08140201560607259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Sample dataset for regression\n",
    "X_reg = df[['StudyHours']]\n",
    "y_reg = df['PrevExamScore']\n",
    "\n",
    "# Initialize a linear regression model\n",
    "reg_model = LinearRegression()\n",
    "\n",
    "# Perform 5-fold cross-validation using R-squared as the metric\n",
    "cv_scores_r2 = cross_val_score(reg_model, X_reg, y_reg, cv=5, scoring='r2')\n",
    "\n",
    "print(f'Cross-validation R-squared scores: {cv_scores_r2}')\n",
    "print(f'Mean R-squared score: {np.mean(cv_scores_r2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d84993c3-079c-423e-962b-637129d41f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Coefficients: [0.08153909 0.01180619]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Lasso model with alpha (Î») as the regularization parameter\n",
    "lasso_model = Lasso(alpha=0.01)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Display the coefficients of the features\n",
    "print(f\"Lasso Coefficients: {lasso_model.coef_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90775182-c4aa-4058-a967-363ea6fc99d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['PrevExamScore']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Define forward selection function\n",
    "def forward_selection(X, y):\n",
    "    remaining_features = set(X.columns)\n",
    "    selected_features = []\n",
    "    current_score = 0.0\n",
    "    best_score = 0.0\n",
    "    \n",
    "    while remaining_features:\n",
    "        scores_with_candidates = []\n",
    "        for feature in remaining_features:\n",
    "            features_to_test = selected_features + [feature]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X[features_to_test], y, test_size=0.2, random_state=42)\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            score = r2_score(y_test, y_pred)\n",
    "            scores_with_candidates.append((score, feature))\n",
    "        \n",
    "        # Select the feature with the best score\n",
    "        scores_with_candidates.sort(reverse=True)\n",
    "        best_score, best_feature = scores_with_candidates[0]\n",
    "        \n",
    "        if current_score < best_score:\n",
    "            remaining_features.remove(best_feature)\n",
    "            selected_features.append(best_feature)\n",
    "            current_score = best_score\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Apply forward selection\n",
    "best_features = forward_selection(X, y)\n",
    "print(\"Selected features:\", best_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
